{"title":"PSTAT 5A: Lecture 21","markdown":{"yaml":{"title":"PSTAT 5A: Lecture 21","subtitle":"Review of Probability","author":"Ethan P. Marzban","date":"6/12/23","format":{"revealjs":{"html-math-method":"mathjax","theme":["default","custom.scss"],"incremental":true,"logo":"5a_hex.png","template-partials":["title-slide.html"]}},"editor":"source","title-slide-attributes":{"data-background-image":"5a_hex.png","data-background-size":"contain","data-background-opacity":"0.5","data-background-position":"left"}},"headingText":"Probability","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nlibrary(tidyverse)\nlibrary(ggthemes)\n```\n\n\n## Basics of Probability\n\n- **Experiment:** A procedure we can repeat and infinite number of times, where each time we repeat the procedure the same fixed set of *things* (i.e. **outcomes**) can occur.\n\n    - **Outcome Space:** The set of all outcomes associated with an experiment\n    \n- Different ways to express an outcome space: as a set, using a table (for two-stage experiments), or using a tree.\n\n- **Event:** A subset of $\\Omega$\n\n    - I.e. an event is a set comprised of outcomes.\n\n## Example\n\n**Toss a fair coin twice, and record the outcome of each toss**\n\n- Outcome Space:\n\n    - As a set: $\\Omega = \\{(H, H), \\ (H, T), \\ (T, H), \\ (T, T) \\}$\n    - As a table:\n\n:::{.fragment}\n<table>\n\t<tr>\n    \t<td></td>\n        <td style=\"text-align:center\">H</td>\n        <td style=\"text-align:center\">T</td>\n    </tr>\n    <tr>\n    \t<td>H</td>\n        <td>(H, H)</td>\n        <td>(H, T)</td>\n    </tr>\n    <tr>\n    \t<td>T</td>\n        <td>(T, H)</td>\n        <td>(T, T)</td>\n    </tr>\n</table>\n:::\n\n\n## Example\n\n**Toss a fair coin twice, and record the outcome of each toss**\n\n:::{.nonincremental}\n- Outcome Space:\n\n    - As a tree:\n:::\n\n:::{.fragment}\n```{dot}\n//| fig-width: 10\n//| fig-height: 4\ndigraph tree_diagram {\n    layout = dot\n    rankdir = UD\n    splines = false\n    bgcolor = \"#f0ebd8\"\n    edge [arrowsize = 0.5, color = coral4]\n    node [shape=plaintext]\n\nbase [label = \"o\"]\n\nH1 [label = \"H\"]\nT1 [label = \"T\"]\n\nH21 [label = \"H\"]\nT21 [label = \"T\"]\nH22 [label = \"H\"]\nT22 [label = \"T\"]\n\nbase -> {H1, T1}\n\nH1 -> {H21, T21}\nT1 -> {H22, T22}\n\n\n}\n```\n:::\n\n## Example\n\n**Toss a fair coin twice, and record the outcome of each toss**\n\n- Some events:\n\n    - \"At least one heads:\" $\\{(H, T), \\ (T, H), \\ (H, H)\\}$\n    - \"At most one heads:\" $\\{(T, T), \\ (T, H), \\ (H, T)\\}$\n    - \"No heads and no tails:\" $\\varnothing$\n    \n## Unions, Intersections, Complements\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n![](VennDiagrams/a_complement.svg){width=50%}\n:::\n\n::: {.column width=\"50%\"}\n:::{style=\"text-align:center\"}\n\n<br />\n$A^\\complement$ <br /> (complement)\n:::\n:::\n\n::::\n\n::::{.columns}\n\n::: {.column width=\"50%\"}\n![](VennDiagrams/ab_intersect_shaded.svg){width=50%}\n:::\n\n::: {.column width=\"50%\"}\n:::{style=\"text-align:center\"}\n\n<br />\n$A \\cap B$ <br /> (intersection)\n:::\n:::\n\n::::\n\n::::{.columns}\n\n::: {.column width=\"50%\"}\n![](VennDiagrams/ab_union.svg){width=50%}\n:::\n\n::: {.column width=\"50%\"}\n:::{style=\"text-align:center\"}\n\n<br />\n$A \\cup B$ <br /> (union)\n:::\n:::\n\n::::\n\n## DeMorgan's Laws\n\n- $(E \\cap F)^\\complement = (E^\\complement) \\cup (F^\\complement)$\n\n    - The opposite of \"*E* and *F*\" is \"either *E* did not occur, or *F* did not occur (or both)\"\n  \n\\\n\n- $(E \\cup F)^\\complement = (E^\\complement) \\cap (F^\\complement)$\n\n    - The opposite of \"*E* or *F*\" is \"neither *E* nor *F* occur\"\n    \n\n## Probability\n\n- Two main ways of defining the **probability** of an event $E$.\n\n- **Classical Approach:** $\\displaystyle \\mathbb{P}(E) = \\frac{\\#(E)}{\\#(\\Omega)}$\n\n    - Can be used only when we have equally likely outcomes.\n    \n    - Keywords to look out for: at random, randomly, uniformly, etc.\n    \n- **Long-Run Relative Frequency Approach:** Define $\\mathbb{P}(E)$ to be the relative frequency of the times we observe $E$, after an infinite number of repetitions of our experiment.\n\n## Relative Frequencies\n\nSuppose we toss a coin and record whether the outcome lands `heads` or `tails`, and further suppose we observe the following tosses:\n\n:::{.fragment}\n:::{style=\"text-align:center\"}\n`H`, \\ `T`, \\  `T`, \\  `H`, \\  `T`, \\  `H`, \\  `H`, \\  `H`, \\  `T`, \\  `T`\n:::\n:::\n\n- To compute the relative frequency of `heads` after each toss, we count the number of times we observed `heads` and divide by the total number of tosses observed.\n\n---\n\n| Toss | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |\n|:----:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n| Outcome| `H` | `T` | `T` | `H` | `T` | `H` | `H` | `H` | `T` | `T` | \n| Raw freq. of `H` | 1 | 1 | 1 | 2 | 2 | 3 | 4 | 5 | 5 | 5 |\n| Rel. freq of `H` | 1/1 | 1/2 | 1/3 | 2/4 | 2/5 | 3/6 | 4/7 | 5/8 | 5/9 | 5/10 |\n\n```{r, fig.height = 3.5}\n#| echo: false\n\nlibrary(tidyverse)\nlibrary(ggthemes)\n\nx <- 1:10\ny <- c(1, 1/2, 1/3, 2/4, 2/5, 3/6, 4/7, 5/8, 5/9, 5/10)\n\ndata.frame(x = x, y = y) %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_point(size = 2) +\n  geom_line() +\n  theme_economist(base_size = 18) +\n  theme(panel.background = element_rect(\"#f0ebd8\"),\n        plot.background = element_rect(fill = \"#f0ebd8\"),\n        axis.title.y = element_text(size = 16,\n                                    margin = margin(\n                                      t = 0, \n                                      r = 10,\n                                      b = 0, \n                                      l = 0)),\n        axis.title.x = element_text(size = 16)\n  ) +\n  ggtitle(\"Relative Frequencies of Heads\")\n```\n\n---\n\n:::{.nonincremental}\n- It turns out (by what is known as the **Weak Law of Large Numbers**) that, regardless of the experiment and event, the relative frequencies will converge to some fixed value.\n:::\n\n- What the long-run frequencies approach to probability says is to define this value to be the probability of the event.\n\n:::{.fragment}\n```{r, fig.height = 3.5}\n#| echo: false\n\nlibrary(tidyverse)\nlibrary(ggthemes)\n\nset.seed(5)\n\nx <- 1:200\ny <- cumsum(sample(c(0, 1), size = 200, replace = T))/x\n\ndata.frame(x = x, y = y) %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_line() +\n  theme_economist(base_size = 18) +\n  theme(panel.background = element_rect(\"#f0ebd8\"),\n        plot.background = element_rect(fill = \"#f0ebd8\"),\n        axis.title.y = element_text(size = 16,\n                                    margin = margin(\n                                      t = 0, \n                                      r = 10,\n                                      b = 0, \n                                      l = 0)),\n        axis.title.x = element_text(size = 16)\n  ) +\n  ggtitle(\"Relative Frequencies of Heads\")\n```\n:::\n\n## Conditional Probability\n\n- $\\mathbb{P}(E \\mid F)$: represents our updated beliefs on $E$, in the presence of the information contained in $F$.\n    \n    - Only defined when $\\mathbb{P}(F) \\neq 0$\n    \n    - Computed as $\\displaystyle \\mathbb{P}(E \\mid F) = \\frac{\\mathbb{P}(E \\cap F)}{\\mathbb{P}(F)}$\n    \n- **Multiplication Rule:** $\\mathbb{P}(E \\cap F) = \\mathbb{P}(E \\mid F) \\cdot \\mathbb{P}(F) = \\mathbb{P}(F \\mid E) \\cdot \\mathbb{P}(E)$\n\n- **Bayes' Rule:** $\\displaystyle \\mathbb{P}(E \\mid F) = \\frac{\\mathbb{P}(F \\mid E) \\cdot \\mathbb{P}(E)}{\\mathbb{P}(F)}$\n\n- **Law of Total Probability:** $\\displaystyle \\mathbb{P}(E) = \\mathbb{P}(E \\mid F) \\cdot \\mathbb{P}(F) + \\mathbb{P}(E \\mid F^\\complement) \\cdot \\mathbb{P}(F^\\complement)$\n\n## Independence\n\n- Two events $E$ and $F$ are **independent** if any of the following are true:\n\n    - $\\mathbb{P}(E \\mid F) = \\mathbb{P}(E)$\n    - $\\mathbb{P}(F \\mid E) = \\mathbb{P}(F)$\n    - $\\mathbb{P}(E \\cap F) = \\mathbb{P}(E) \\cdot \\mathbb{P}(F)$\n\n# Counting\n\n\n## Fundamental Principle of Counting\n\n:::{.nonincremental}\n::: callout-important\n## Fundamental Principle of Counting\n\n::: {style=\"font-size: 30px\"}\nIf an experiment consists of $k$ stages, where the $i$^th^ stage has $n_i$ possible configurations, then the total number of elements in the outcome space is\n$$ n_1 \\times n_2 \\times \\cdots \\times n_k $$\n\n:::\n:::\n:::\n\n- E.g.: number of ice cream scoops consisting of one flavor (Vanilla, Chocolate, or Matcha) and the one topping (sprinkles or coconut) is $3 \\times 2 = 6$.\n\n\n\n\n## Counting Formulas\n\n- **_n_ factorial:** $n! = n \\times (n - 1) \\times \\cdots \\times (3) \\times (2) \\times (1)$\n\n    - $0! = 1$\n    \n- **_n_ order _k_**: $\\displaystyle (n)_k = \\frac{n!}{(n - k)!}$\n\n- **_n_ choose _k_**: $\\displaystyle \\binom{n}{k} = \\frac{n!}{k! \\cdot (n - k)!}$\n\n\n\\\n\n- For more practice, I encourage you to take a look at Homework 2, along with some of the MT1 practice problems.\n\n\n## Example (Chalkboard)\n\n\n::: callout-tip\n## Chalkboard Exercise 1\n\n::: {style=\"font-size: 25px\"}\nAn observational study tracked whether or not a group of individuals were taking a particular drug, along with whether or not they had high blood pressure. \n\n```{r}\n#| echo: false\n\ndf <- matrix(c(\n  rep(c(\"Taking\", \"High\"), 10),\n  rep(c(\"Taking\", \"Low\"), 20),\n  rep(c(\"Not Taking\", \"High\"), 10),\n  rep(c(\"Not Taking\", \"Low\"), 10)\n), ncol = 2, byrow = T)\ncolnames(df) <- c(\"Drug\", \"Blood Pressure\")\ndf <- data.frame(df)\ndf$Drug <- factor(df$Drug)\ndf$Blood.Pressure <- factor(df$Blood.Pressure)\n\ntable(df)\n```\n\nA participant is selected at random.\n\n- What is the probability that they have high blood pressure?\n- What is the probability that they have either high blood pressure or are taking the drug?\n- If they have high blood pressure, what is the probability that they are taking the drug?\n- Are the events \"taking the drug\" and \"having high blood pressure\" independent?\n:::\n:::\n\n\n\n## Example (Chalkboard)\n\n::: callout-tip\n## Chalkboard Exercise 2\n\n::: {style=\"font-size: 25px\"}\nA recent survey at *Ralph*'s grocery store revealed that 25\\% of people buy soda and 40\\% of people by fruit. Additionally, 40\\% of people who buy soda also buy fruit. If a customer at *Ralph's* is selected at random....\n\n- ... what is the probability that they buy either soda or fruit?\n- ... what is the probability that they buy neither soda nor fruit?\n:::\n:::\n\n\n\n# Random Variables\n\n## Random Variables\n\n- A **random variable**, loosely speaking, is a variable that tracks some sort of outcome of an experiment.\n\n    - E.g. \"number of heads in 10 coin tosses\"\n    - E.g. \"height of a randomly-selected building from downtown Santa Barbara\"\n    \n- Every random variable has a **state space**, which is the set of values the random variable can attain. We use the notation $S_X$ to denote the state space of the random variable $X$.\n\n    - If $S_X$ has jumps, we say $X$ is **discrete**.\n    - Otherwise, we say $X$ is **continuous**\n    \n## Discrete Random Variables {style=\"font-size:32px\"}\n\n- Discrete random variables are characterized by a **probability mass function** (p.m.f.), which expresses not only the values the random variable can take but also the probability with which it attains those values.\n\n    - We use the notation $\\mathbb{P}(X = k)$ to denote the probability that a random variable $X$ attains the value of $k$.\n    \n- **Expected Value:** $\\displaystyle \\mathbb{E}[X] = \\sum_{\\text{all $k$}} k \\cdot \\mathbb{P}(X = k)$\n\n- **Variance:** \n\n    - $\\displaystyle \\mathrm{Var}(X) = \\sum_{\\text{all $k$}}(k - \\mathbb{E}[X])^2 \\cdot \\mathbb{P}(X = k)$\n    \n    - $\\displaystyle \\mathrm{Var}(X) = \\left( \\sum_{\\text{all $k$}} k^2 \\cdot \\mathbb{P}(X = k) \\right) - (\\mathbb{E}[X])^2$\n    \n## Continuous Random Variables\n\n- Continuous random variables are characterized by a **probability density function** (p.d.f.), which is a function $f_X(x)$ satisfying:\n\n    - nonnegativity: $f_X(x) \\geq 0$ for all $x \\in \\mathbb{R}$\n    - area equals 1: the area under the graph of $f_X(x)$ should be 1\n    \n- The term **density curve** refers to the graph of the p.d.f.\n\n    - Probabilities are found as areas underneath the density curve\n    \n- **Cumulative Distribution Function:** $F_X(x) = \\mathbb{P}(X \\leq)\n\n- $\\mathbb{P}(X = k) = 0$ if $X$ is continuous.\n\n## Distributions\n\n- Binomial: $X \\sim \\mathrm{Bin}(n, \\ p)$\n\n- Uniform: $X \\sim \\mathrm{Unif}(a, \\ b)$\n\n- Normal: $X \\sim \\mathcal{N}(\\mu, \\ \\sigma)$\n\n    - Standardization"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":"mathjax","slide-level":2,"to":"revealjs","incremental":true,"output-file":"ProbRev.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.2.335","auto-stretch":true,"title":"PSTAT 5A: Lecture 21","subtitle":"Review of Probability","author":"Ethan P. Marzban","date":"6/12/23","editor":"source","title-slide-attributes":{"data-background-image":"5a_hex.png","data-background-size":"contain","data-background-opacity":"0.5","data-background-position":"left"},"theme":["default","custom.scss"],"logo":"5a_hex.png","template-partials":["title-slide.html"]}}}}
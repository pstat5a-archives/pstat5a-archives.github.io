{"title":"Lab07","markdown":{"yaml":{"title":"Lab07","subtitle":"Percentiles, Default Values, and Testing Distributional Fits","author":[{"name":"PSTAT 5A, with Ethan Marzban","affiliations":[{"name":"Spring 2023"}]}],"author-title":"Course","affiliation-title":"Quarter","format":"html","title-block-banner":"#4144a6","css":"styles.css"},"headingText":"Percentiles","containsRefs":false,"markdown":"\n\n------------------------------------------------------------------------\n\n\nAs we have seen in lecture, confidence intervals for a population parameter $\\theta$ take the form\n$$ \\widehat{\\theta} \\pm c \\cdot \\mathrm{s.e.} $$\nwhere $\\mathrm{s.e.}$ denotes the standard error (i.e. standard deviation) of the point estimator $\\widehat{\\Theta}$, and $c$ is an appropriately-selected percentile from the distribution of $\\widehat{\\Theta}$. \n\nUp until now, we have primarily been finding the constant $c$ using the various tables at our disposal (i.e. the normal table, and the $t$ table). Though being able to read these tables is a useful skill (and a skill that is potentially testable on quizzes and exams...), using computers to compute these percentiles can greatly increase efficiency. \n\nOn Homework 6 we were exposed to the function `scipy.stats.norm.ppf()` to compute the percentiles of the normal distribution. Recall that the syntax\n```{python}\n#| eval: False\n\nscipy.stats.norm.ppf(p, m, s)\n```\ncomputes the `p`^th^ percentile of the $\\mathcal{N}$(`m`, `s`) distribution. There are analagous functions that allow us to compute percentiles of other distributions; for example, `scipy.stats.t.ppf()` can be used to find the percentiles of the $t$ distribution.\n\n\n:::{.callout-important}\n## Task 1\n\na. Find the 10^th^ percentile of the $t_{31}$ distribution and check that this value agrees with the value provided in the $t-$table appearing on the course website. (Remember that the percentile you find will need to be scaled by $-1$ to match the value provided in the table.)\n\nb. Find the 0.5^th^ percentile of the $t_{11}$ distribution and check that this value agrees with the value provided in the $t-$table appearing on the course website. (Remember that the percentile you find will need to be scaled by $-1$ to match the value provided in the table.)\n\n:::\n\n\n## Default Values in a Function\n\nBy the way, it should be noted that some arguments in certain functions have what are known as **default values**. For example, the code `scipy.stats.norm.ppf(0.025)` will run even though we haven't explicitly specified an `m` and `s` value. If we consult the [help file](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html) for the `scipy.stats.norm.ppf()` function, we will see that the arguments `m` and `s` are assigned default values of `0` and `1` respectively. What this means is that, we don't explicitly specify a value for `m` or `s`, Python will automatically assign them a value of `0` and `1`, respectively.\n```{python}\nimport scipy.stats as sps\nsps.norm.ppf(0.025)\n```\n\n\n:::{.callout-important}\n## Task 2\n\na. What are the arguments that the function `sps.t.ppf()` (assuming we have imported `scipy.stats` as `sps`) takes?\n\nb. How many of the arguments take default values? What are the default values?\n:::\n\nWhen defining a function ourselves, we can also specify default values for some (or even all) of the arguments! The syntax we use is:\n```{python}\n#| eval: False\n\ndef <function name>(<arg1> = <default1>, <arg2> = <default2>, ...):\n  <body of function>\n```\nFor example,\n```{python}\ndef f(x, y = 1):\n  return x + y\n\nf(3)\n```\n\n:::{.callout-important}\n## Task 3\n\nWrite a function called `dice_roll()` that takes in two inputs:\n\n- `num_sides` (with a default value of 6)\n- `num_rolls` (with a default value of 1)\n\nthat simulates rolling a `num_sides`-sided die `num_rolls` times. Test that your function behaves as follows:\n\n```{python}\n#| echo: False\nimport numpy as np\nimport random as rnd\n\ndef dice_roll(num_sides = 6, num_rolls = 1):\n  return rnd.choices(np.arange(0, 7), k = num_rolls)\n```\n\n```{python}\ndice_roll(12, 5) # rolling a 12-sided die 5 times\n```\n\n```{python}\ndice_roll(12) # rolling a 12-sided die once\n```\n\n```{python}\ndice_roll() # rolling a 6-sided die once\n```\n\n:::\n\n\n## Testing Distributional Fits\n\nIf you recall, one of the first questions we need to ask ourselves when constructing a confidence interval for a population mean is whether or not the underlying distribution is normal. This begs the question: how can we tell if something follows a normal distribution?\n\nOne idea might be to look at a histogram. For example, given a list of numbers `x` sampled from an unknown distribution, we could simply generate a histogram of `x` and see if it is bell-shaped:\n```{python}\n#| echo: False\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\nimport numpy as np\nnp.random.seed(10)\n\nx = sps.norm.rvs(size = 100)\n\nplt.figure(figsize=(6, 3))\nplt.hist(x, edgecolor = \"white\", density = True);\nplt.xlabel(\"x\");\nplt.ylabel(\"y\");\nplt.title(\"Histogram of x\");\n```\n\nThis is, however, **not** a good idea in practice, as there are many distributions that have bell-shaped density curves but are *not* normal; for example, $t-$distribution. In other words, even though the histogram above is bell-shaped, how do we know it came from a normal distribution and not a $t-$distribution? The answer is- we don't!\n\nInstead, statisticians and datascientists use **QQ-plots** to assess distributional fits. The general idea of a QQ-plot is as follows: if `x` truly was sampled from a normal distribution, its sample percentiles should correspond closely with the percentiles of the standard normal distribution. As such, a QQ-plot plots the sample percentiles (sometimes called **quantiles**, hence the name QQ-plot as opposed to PP-plot) against the standard normal percentiles. \\\n\nThere are several different functions in several different Python modules which can be used to construct QQ-plots; the one we will use is the `probplot()` function from the `scipy.stats` package:\n```{python}\n#| echo: False\nplt.figure(figsize=(6, 3))\nsps.probplot(x, plot = plt);\n```\n```{python}\n#| eval: False\nplt.figure(figsize=(6, 3))\nsps.probplot(x, plot = plt);\n```\nWhy is Python displaying a diagonal line? Well, let's think about what our QQ-plot would look like if `x` *were* actually sampled from a normal distribution. Again, *all* sample quantiles of `x` would be pretty close to the corresponding quantiles of the standard normal distribution; i.e. the QQ-plot would look pretty close to a diagonal line! \n\nSaid differently: significant deviations from the diagonal line in a QQ-plot indicate non-normality. The plot above does not have too many significant deviations from the line, meaning we would say that `x` is likely sampled from a normal distribution. As an example of a QQ-plot that indicates non-normality:\n```{python}\n#| echo: False\n\nplt.figure(figsize=(6, 3))\ny = sps.t.rvs(1, size = 100)\nsps.probplot(y, plot = plt);\n```\n\n:::{.callout-tip}\n## Note\nWhen using a QQ-plot to assess normality, always check the behavior in the tails (i.e. left- and right-extremes of the plot), as this is often where non-normality becomes the clearest.\n:::\n\n:::{.callout-important}\n## Task 4\n\nGenerate a series of 100 draws from the $\\mathcal{N}(3, \\ 2.1)$ distribution and store these in a variable called `x`. Generate another series of 100 draws, this time from the $t_{2}$ distribution, and store these in a variable called `y`. Then, generate QQ-plots of both `x` and `y`, and comment on how you would be able to tell that `x` was normally distributed whereas `y` was not, even if you hadn't been told explicitly which distributions `x` and `y` came from. **Hint:** you may need to look up the help file on `scipy.stats.probplot()` when making the QQ-plot for `y`.\n\n:::\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../styles.css","styles.css"],"toc":true,"output-file":"lab07.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":"sandstone","title":"Lab07","subtitle":"Percentiles, Default Values, and Testing Distributional Fits","author":[{"name":"PSTAT 5A, with Ethan Marzban","affiliations":[{"name":"Spring 2023"}]}],"author-title":"Course","affiliation-title":"Quarter","title-block-banner":"#4144a6"},"extensions":{"book":{"multiFile":true}}}}}
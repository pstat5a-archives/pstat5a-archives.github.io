{"title":"PSTAT 5A: Lecture 12","markdown":{"yaml":{"title":"PSTAT 5A: Lecture 12","subtitle":"Inference on the Mean","author":"Ethan P. Marzban","date":"5/11/23","format":{"revealjs":{"html-math-method":"mathjax","theme":["default","custom.scss"],"incremental":true,"logo":"5a_hex.png","template-partials":["title-slide.html"]}},"editor":"source","title-slide-attributes":{"data-background-image":"5a_hex.png","data-background-size":"contain","data-background-opacity":"0.5","data-background-position":"left"}},"headingText":"Previously","headingAttr":{"id":"","classes":[],"keyvalue":[["style","font-size:30px"]]},"containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nlibrary(tidyverse)\nlibrary(ggthemes)\n```\n\n\n- Over the course of the past few lectures, we've been dealing primarily with population proportions.\n\n- A natural point estimate of $p$ is $\\widehat{P}$, the sample proportion, and used the Central Limit Theorem to figure out what its sampling distribution is.\n\n- We then used the sampling distribution of $\\widehat{P}$ to construct confidence intervals for the true proportion $p$.\n\n- Now we will turn our attention to a different population parameter.\n\n## Leadup {style=\"font-size:30px\"}\n\n- Recall from last lecture that any of the descriptive statistics we discussed in Week 1 can be viewed as population parameters, when they apply to the population.\n    - E.g. population proportion ($p$), population variance ($\\sigma^2$), etc.\n- Of particular interest to statisticians is often the **population mean**, $\\mu$. \n- Let's try and draw some analogies from our work with population proportions.\n- When trying to make inferences on a population proportion $p$, we used the sample proportion $\\widehat{P}$ as a proxy (specifically, a **point estimator**). \n    - Any guesses on what we might use as a point estimator of $\\mu$?\n    - That's right- the **sample mean** $\\overline{X}$!\n\n## Notation {style=\"font-size:30px\"}\n\n- Again, it will be useful to establish some notation:\n    - $\\mu$ represents the population mean, and is deterministic (i.e. fixed) but unknown.\n    - $\\overline{X}$ represents the mean *of some hypothetical sample*, and is therefore random (as different samples result in different sample means)\n    - $\\overline{x}$ represents the mean *of a specific sample*, and is therefore deterministic (i.e. \"we've taken *this particular sample right here* and computed its mean).\n\n- Just as $\\widehat{P}$ has a **sampling distribution**, so too does $\\overline{X}$.\n\n- The sampling distribution of $\\overline{X}$, however, will end up requiring a bit more work.\n\n## General Confidence Intervals {style=\"font-size:30px\"}\n\n- We will follow the general idea we used before of constructing confidence intervals as $\\widehat{\\theta} \\pm \\mathrm{m.e.}$.\n\n- In this case, we use $\\overline{X}$ as our point estimator. \n\n- It turns out that, assuming the population mean is $\\mu$ and the population standard deviation is $\\sigma$, and if $\\overline{X}$ denotes the mean of a sample of size $n$, we have that\n$$ \\mathrm{SD}(\\overline{X}) = \\frac{\\sigma}{\\sqrt{n}} $$\n\n- Therefore, our confidence intervals will take the form\n$$ \\overline{X} \\pm c \\cdot \\frac{\\sigma}{\\sqrt{n}} $$\nwhere the constant $c$ depends on both the sampling distribution of $\\overline{X}$ as well as the confidence level.\n\n\n## Normal Population {style=\"font-size:30px\"}\n\n- Let's work on finding the sampling distribution of $\\overline{X}$.\n\n- It turns out that the first thing we need to ask is whether the underlying population is normally distributed or not.\n\n- If the underlying population *is* normally distributed [again with population mean $\\mu$ and population standard deviation $\\sigma$], we have that\n$$ \\frac{\\overline{X} - \\mu}{\\sigma / \\sqrt{n}} \\sim \\mathcal{N}(0, \\ 1) $$\nmeaning the constant $c$ should be selected as the appropriate percentile of the *standard normal* distribution:\n$$ \\overline{x} \\pm z_\\alpha \\cdot \\frac{\\sigma}{\\sqrt{n}} $$\n\n## Worked-Out Example {style=\"font-size:30px\"}\n\n:::{.fragment}\n::: callout-tip\n## Worked-Out Example 1\n\n:::{.nonincremental}\n::: {style=\"font-size: 30px\"}\nThe heights of adult males is assumed to follow a normal distribution with mean 70 in and standard deviation 15 in. A representative sample of 120 adult males is taken, and the average height of males in this sample is recorded.\n\na. What is the random variable of interest?\nb. Is the value of 70 in a population parameter or a sample statistic?\nc. What is the probability that the average height of males in the sample is between 69.5 in and 71.5 in? \n\n:::\n:::\n:::\n:::\n\n## Solutions {style=\"font-size:30px\"}\n\na) $\\overline{X} =$ the average height of a sample of 120 adult males. \n\nb) The value of 70 in is a population parameter, as it is the true average height of all adult males.\n\nc) The quantity we seek is $\\mathbb{P}(69.5 \\leq \\overline{X} \\leq 71.5)$. Because the population is normally distributed, we can use our result above to conclude\n$$ \\overline{X} \\sim \\mathcal{N}\\left( 70, \\ \\frac{15}{\\sqrt{120}} \\right) \\sim \\mathcal{N}\\left( 70, \\ 1.369 \\right) $$\n\n- To find $\\mathbb{P}(69.5 \\leq \\overline{X} \\leq 71.5)$, we therefore utilize the same techniques we used previously, when dealing with normal distribution problems:\n$$\\mathbb{P}(69.5 \\leq \\overline{X} \\leq 71.5) = \\mathbb{P}(\\overline{X} \\leq 71.5) - \\mathbb{P}(\\overline{X} \\leq 69.5) $$\n\n## Solutions {style=\"font-size:30px\"}\n\n:::{.nonincremental}\n- The associated $z-$scores are\n\\begin{align*}\n  z_1     & = \\frac{71.5 - 70}{\\left( \\frac{15}{\\sqrt{120}} \\right)} \\approx 1.10    \\\\\n  z_2     & = \\frac{69.5 - 70}{\\left( \\frac{15}{\\sqrt{120}} \\right)} \\approx -0.37\n\\end{align*}\n:::\n\n- The associated probabilities (from a $z-$table) are $0.8643$ and $0.3557$, respectively, meaning the desired probability is\n$$ 0.8643 - 0.3557 = \\boxed{ 0.5086 = 50.86\\% } $$\n\n---\n\n## Non-Normal Population {style=\"font-size:30px\"}\n\n- Alright, so that explains what to do if the population values follow a normal distribution.\n\n- But what if they don't? In real-world settings, we don't typically get to know exactly what the population distribution is. \n\n- If our population is *not* normally distributed, we need to ask ourselves whether we have a \"large enough sample\".\n\n- Admittedly, there isn't a single agreed-upon cutoff for \"large enough\"- for the purposes of this class, we will use $n \\geq 30$ to mean \"large enough\" and $n < 30$ to therefore be \"not large enough.\"\n\n## Non-Normal Population, $n < 30$ {style=\"font-size:30px\"}\n\n- If the population is non-normal, and the sample size is not large enough...\n\n- ... we can't do anything. \n\n- More specifically, there aren't any results we can use to confidently make inferences about the population mean- there is just too much uncertainty, between the uncertainty regarding the population's distribution *and* the small sample size.\n\n\n## Non-Normal Population, $n \\geq 30$ {style=\"font-size:30px\"}\n\n- If the population is non-normal, and the sample size *is* large enough...\n\n- ... we're still (perhaps surprisingly) in business!\n\n- It turns out that if $n$ is large enough,\n$$ \\frac{\\overline{X} - \\mu}{\\sigma / \\sqrt{n}} \\sim \\mathcal{N}(0, \\ 1) $$\nthat is, the sample mean once again has a normal sampling distribution!\n\n- In fact, this is such an important result, we give it a name:\n\n## Central Limit Theorem for the Sample Mean {style=\"font-size:30px\"}\n\n:::{.fragment}\n:::{.callout-important}\n## **Central Limit Theorem for the Sample Mean**\n::: {style=\"font-size: 28px\"}\nIf we have reasonably representative samples of large enough size $n$, taken from a population with true mean $\\mu$ and true standard deviation $\\sigma$, then\n$$ \\frac{\\overline{X} - \\mu}{\\sigma / \\sqrt{n}} \\sim \\mathcal{N}\\left(0, \\ 1 \\right) $$\nor, equivalently,\n$$ \\overline{X} \\sim \\mathcal{N}\\left( \\mu, \\ \\frac{\\sigma}{\\sqrt{n}} \\right) $$\nwhere $\\overline{X}$ denotes the sample mean.\n:::\n:::\n:::\n\n## Worked-Out Example {style=\"font-size:30px\"}\n\n:::{.fragment}\n::: callout-tip\n## Worked-Out Example 2\n\n:::{.nonincremental}\n::: {style=\"font-size: 30px\"}\nThe temperatures collected at all weather stations in Antarctica follow some unknown distribution with unknown mean and known standard deviation 8^o^F. A researcher records the temperature measurements from a representative sample of 81 different weather stations, and finds the average temperature to be 26^o^F.\n\na. What is the population?\nb. What is the sample?\nc. Define the random variable of interest.\nd. What is the probability that this observed average of 26^o^F lies within 1^o^F of the true average temperature across all weather stations in Antarctica?\ne. Construct a 90\\% confidence interval for the true average temperature across all weather stations in Antarctica.\n\n:::\n:::\n:::\n:::\n\n## Solutions {style=\"font-size:30px\"}\n\na. The population is the set of all weather stations in Antarctica.\n\nb. The sample is the 81 weather stations selected by the researcher.\n\nc. The random variable of interest is $\\overline{X}$, the average temperature across 81 randomly-selected weather stations in Antarctica.\n\n:::{.fragment}\n**Part (d):** This is where things get interesting!\n:::\n\n- Is the population normally distributed?\n    - No. Or, at least, we don't know for certain, so it's safer *not* to assume it is.\n- Is our sample size large enough to invoke the CLT?\n    - Yes, since $n = 81 \\geq 30$.\n- Therefore, the CLT applies and tells us that\n$$ \\overline{X} \\sim \\mathcal{N}\\left(\\mu, \\ \\frac{8}{\\sqrt{81}} \\right) \\sim \\mathcal{N}\\left(\\mu, \\ \\frac{8}{9} \\right) $$\n\n## Solutions {style=\"font-size:30px\"}\n\n- Again, what we have found is \n$$ \\overline{X} \\sim \\mathcal{N}\\left(\\mu, \\ \\frac{8}{\\sqrt{81}} \\right) \\sim \\mathcal{N}\\left(\\mu, \\ \\frac{8}{9} \\right) $$\n\n- We seek $\\mathbb{P}(\\mu - 1 \\leq \\overline{X} \\leq \\mu + 1)$, which we first write as\n$$ \\mathbb{P}(\\overline{X} \\leq \\mu + 1) - \\mathbb{P}(\\overline{X} \\leq \\mu - 1) $$\n\n- Computing the necessary $z-$scores yields\n\\begin{align*}\n  z_1   &  = \\frac{(\\mu + 1) - \\mu}{8/9} = \\frac{9}{8} \\approx 1.13    \\\\\n  z_2   &  = \\frac{(\\mu - 1) - \\mu}{8/9} = -\\frac{9}{8} \\approx -1.13\n\\end{align*}\n\n## Solutions {style=\"font-size:30px\"}\n\n- The corresponding values from the normal table are $0.8708$ and $0.1292$, respectively, meaning the desired probability is\n$$ 0.8708 - 0.1292 = \\boxed{74.16\\%} $$\n\n## Unknown $\\sigma$? {style=\"font-size:28px\"}\n\n- Notice that in the previous worked-out example (and, indeed, in the CLT for sample means), we need information on the true population standard deviation $\\sigma$.\n\n- What happens if we don't have access to $\\sigma$?\n\n- Well, we encountered a somewhat similar situation in our discussion on proportions; the standard error of $\\widehat{P}$ depended on $p$, which proves to be a problem in practice (as, again, the true value of $p$ is often unknown).\n\n- Does anyone remember how we solved this issue in the context of population proportions?\n    - That's right- we used the substitution approximation!\n    - Specifically, we replaced the unknown parameter ($p$) with a natural point estimator of it.\n\n## Unknown $\\sigma$? {style=\"font-size:28px\"}\n\n- Can anyone propose a point estimator for $\\sigma$?\n\n- That's right; $s$, the sample standard deviation!\n$$ s = \\sqrt{ \\frac{1}{n - 1} \\sum_{i=1}^{n} (X_i - \\overline{X})^2} $$\n\n- In other words, our proposition is to use confidence intervals of the form\n$$ \\overline{x} \\pm c \\cdot \\frac{s}{\\sqrt{n}} $$\n\n- Notice, however, that this introduces additional uncertainty into the problem as $s$ itself is a random variable (different samples result in different sample standard deviations).\n\n- It turns out that the additional uncertainty introduced is so large that we become **no longer able to use the normal distribution.** \n\n## Using $s$ in place of $\\sigma$ {style=\"font-size:28px\"}\n\n- Firstly, recall that we used percentiles of the standard normal distribution because\n$$ \\frac{\\overline{X} - \\mu}{\\sigma / \\sqrt{n}} \\sim \\mathcal{N}(0, \\ 1) $$\n\n- Mathematically, what the above discussion is saying is that the distribution of\n$$ \\frac{\\overline{X} - \\mu}{s / \\sqrt{n}} $$\nis no longer normal.\n\n- It turns out that, still assuming a large enough sample size, the quantity above follows what is known as a **_t_-distribution**.\n\n## The *t-*distribution {style=\"font-size:28px\"}\n\n- The $t-$distribution looks very similar to the standard normal distribution in that it is centered at 1, and has a bell-like density curve.\n\n- However, one key difference is that the $t-$distribution is parameterized by a \n*single* parameter, called the **degrees of freedom**, which we abbreviate $\\mathrm{df}$.\n\n:::{.fragment}\n```{r, fig.height=4.5, fig.width=8, fig.align='center'}\n#| echo: False\ndata.frame(x = c(-3, 3)) %>%\n  ggplot(aes(x)) +\n  stat_function(fun = dt,\n                args = list(df = 1),\n                linewidth = 1.5,\n                aes(colour = \"df = 001\")) +\n  stat_function(fun = dt,\n                args = list(df = 2),\n                linewidth = 1.5,\n                aes(colour = \"df = 002\")) +\n  stat_function(fun = dt,\n                args = list(df = 10),\n                linewidth = 1.5,\n                aes(colour = \"df = 010\")) +\n  stat_function(fun = dt,\n                args = list(df = 100),\n                linewidth = 1.5,\n                aes(colour = \"df = 100\")) +\n  scale_x_continuous(breaks = round(seq(-3, 3, by = 0.5), 1)) +\n  theme_economist_white() +\n  theme(\n    panel.background = element_rect(\"#f0ebd8\"),\n    plot.background = element_rect(fill = \"#f0ebd8\")\n  ) +\n  xlab(\"\") +\n  ylab(\"\") +\n  ylim(c(0, 0.75)) +\n  theme(legend.position = \"right\",\n        legend.background = element_rect(fill=\"#f0ebd8\"),\n        legend.text = element_text(size = 18),\n        legend.title = element_text(size = 20,\n                                    face = \"bold\")\n        ) +\n  labs(colour = bquote(\"Degrees of Freedom\"))\n```\n:::\n\n## The *t-*distribution {style=\"font-size:28px\"}\n\n- Another key property is that, for all finite degrees of freedom, the tails of the *t-*distribution density curve are \"wider\" (i.e. higher) than the tails of the standard normal density curve.\n\n    - What this means is that the *t-*distribution allows for higher probabilities of tail events, thereby incorporating the additional uncertainty injected into our confidence intervals by using $s$ in place of $\\sigma$\n\n- An interesting fact is that the *t-*distribution with $\\infty$ degrees of freedom is equivalent to the standard normal distribution. \n\n    - As such, with greater degrees of freedom, the *t-*distribution - and its percentiles - more and more closely resembles the standard normal distribution.\n\n## Back to Confidence Intervals {style=\"font-size:28px\"}\n\n- Here is the result we've been working toward: with samples of reasonably large size $n$ from a distribution with mean $mu$ and standard deviation $\\sigma$,\n$$ \\frac{\\overline{X} - \\mu}{s / \\sqrt{n}} \\sim t_{n - 1} $$\nwhere $t_{n - 1}$ denotes the $t-$distribution with $n - 1$ degrees of freedom.\n\n- As such, our confidence intervals become\n$$ \\overline{x} \\pm t_{n - 1, \\ \\alpha} \\cdot \\frac{s}{\\sqrt{n}} $$\nwhere $t_{n - 1, \\ \\alpha}$ denotes the appropriate quantile (corresponding to our desired confidence level) of the $t_{n - 1}$ distribution.\n\n## Worked-Out Example {style=\"font-size:30px\"}\n\n:::{.fragment}\n::: callout-tip\n## Worked-Out Example 3\n\n:::{.nonincremental}\n::: {style=\"font-size: 30px\"}\nA sociologist is interested in performing inference on the true average monthly income (in thousands of dollars) of all citizens of the nation of *Gauchonia*. As such, she takes a representative sample of 49 people, and finds that these 49 people have an average monthly income of 2.25 and a standard deviation of 1.66. \n\na. What is the population?\nb. What is the sample?\nc. Define the random variable of interest.\nd. Construct a 95\\% confidence interval for the true average monthly income (in thousands of dollars) of *Gauchonian* citizens.\n\n:::\n:::\n:::\n:::\n\n## Solutions {style=\"font-size:32px\"}\n\na. The population is the set of all *Gauchonian* residents.\n\nb. The sample is the set of 49 *Gauchonian* residents included in the sociologist's sample.\n\nc. The random variable of interest is $\\overline{X}$, the sample average monthly income (in thousands of dollars) of a representative sample of 49 Gauchonian* residents.\n\n## Solutions (cont'd) {style=\"font-size:28px\"}\n\n**Part (d)**\n\n- Is the population normally distributed?\n    - No.\n  \n- Is the sample size large enough?\n    - Yes; $n = 49 \\geq 30$.\n\n- Do we know the population standard deviation?\n    - No, we only know $s$.\n\n- Therefore, we need to use the *t-*distribution with $n - 1 = 49 - 1 = 48$ degrees of freedom.\n\n- Specifically, we need to find the 2.5^th^ percentile of the $t_{48}$ distribution.\n\n- On Monday, during Discussion Section, you will talk about how to read a $t-$table (which is read slightly differently than a standard normal table). \n    - Please keep in mind that that will be potentially testable material on next week's quiz, so be sure to attend Discussion Section!\n\n\n## Solutions (cont'd) {style=\"font-size:24px\"}\n\n- For now, we'll use Python:\n\n:::{.fragment}\n```{python}\n#| echo: True\nimport scipy.stats as sps\nsps.t.ppf(0.025, 48)\n```\n:::\n\n- Therefore, our 95\\% confidence interval takes the form\n$$ \\overline{x} \\pm 2.01 \\cdot \\frac{s}{\\sqrt{49}} $$\nor, equivalently,\n$$ (2.25) \\pm (2.01) \\cdot \\frac{1.66}{7} = 2.25 \\pm 0.477 = \\boxed{[1.773 \\ , \\ 2.727]}$$\n\n- The interpretation of this interval is much the same as our intervals for proportions:\n\n:::{.fragment}\n> We are 95\\% confident that the true average monthly income (in thousands of dollars) of *Gauchonian* residents is between 1.773 and 2.727.\n:::\n\n## General Flowchart\n\n```{mermaid}\ngraph TB\n  A[Is the population Normal?  . ] --> |Yes| B{{Use Normal .}}\n  A --> |No| C[Is n >= 30?  .]\n  C --> |Yes| D[sigma or s?  .]\n  C --> |No| E{{cannot proceed   .}}\n  D --> |sigma| F{{Use Normal .}}\n  D --> |s| G{{Use t }}\n```\n\n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":"mathjax","slide-level":2,"to":"revealjs","incremental":true,"output-file":"Lec12.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.2.335","auto-stretch":true,"title":"PSTAT 5A: Lecture 12","subtitle":"Inference on the Mean","author":"Ethan P. Marzban","date":"5/11/23","editor":"source","title-slide-attributes":{"data-background-image":"5a_hex.png","data-background-size":"contain","data-background-opacity":"0.5","data-background-position":"left"},"theme":["default","custom.scss"],"logo":"5a_hex.png","template-partials":["title-slide.html"]}}}}
{"title":"PSTAT 5A: Lecture 01","markdown":{"yaml":{"title":"PSTAT 5A: Lecture 01","subtitle":"Descriptive Statistics, Part I","author":"Ethan P. Marzban","date":"04/04/23","format":{"revealjs":{"html-math-method":"mathjax","theme":["default","custom.scss"],"incremental":true,"logo":"5a_hex.png","template-partials":["title-slide.html"]}},"editor":"source","title-slide-attributes":{"data-background-image":"5a_hex.png","data-background-size":"contain","data-background-opacity":"0.5","data-background-position":"left"}},"headingText":"Data","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nlibrary(tidyverse)\nlibrary(ggthemes)\n```\n\n\n## What is Data?\n\n![](https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExMWUyYWRhN2M2ZmI3OGFlZTNhMWI2NDY4NDNjNTc4NjM0MzU5NTRlMyZjdD1n/j6TdvPXdAssootjCKZ/giphy.gif)\n\n## What is Data?\n-   According to Merriam-Webster ([source](https://www.merriam-webster.com/dictionary/data)), there are three definitions for **data**:\n\n1)  factual information (such as measurements or statistics) used as a basis for reasoning, discussion, or calculation\n\n2)  information in digital form that can be transmitted or processed\n\n3)  information output by a sensing device or organ that includes both useful and irrelevant or redundant information and must be processed to be meaningful\n\n------------------------------------------------------------------------\n\n::: nonincremental\n-   I like the first definition, mainly because of the phrase \"used as a basis for reasoning, discussion, or calculation.\"\n:::\n\n-   Data, though incredibly useful, is not the be-all and end-all; rather, it should be viewed as a stepping stone for further discussion and/or analysis!\n\n-   Over the span of this course, we will learn the skills of **data literacy**. Loosely speaking, \"data literacy\" refers to the ability to think critically about data, and to understand not only what it is saying but also the ways in which it can be manipulated to deceive.\n\n## Example of Data\n\n- As a concrete example of a **dataset**, let's explore the so-called `palmerpenguins` dataset. \n\n- Collected by Dr. Kristen Gorman at the Palmer Station in Antarctica, this dataset contains various measurements of 344 different penguins Dr. Gorman encountered.\n\n---\n\n```{r, message = F, echo = F}\n#| class-output: hscroll\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n# penguins\ncat(format(as_tibble(penguins))[-c(3L, 1L)], sep = \"\\n\")\n```\n\n```{css, echo=FALSE}\n.hscroll {\n  overflow-x: auto;\n  white-space: nowrap;\n}\n```\n\n- Notice that our data is formatted as a table. This table is what data scientists refer to as the **data matrix.**\n\n---\n\n## The Data Matrix\n\n- Each row of the data matrix above corresponds to an individual penguin. \n\n    - In general, we refer to a given row of the data matrix as an **observational unit**, or **case**.\n\n- For each penguin, we can see that there are observations on several different characteristics; specifically, for each penguin she encountered, Dr. Gorman measured and recorded the penguin's species, island, bill length (in mm), bill depth (in mm), flipper length (in mm), body mass (in grams), sex, and year of observation.\n\n    - Notice that these are the column names in our data matrix above. In general, the columns of the data matrix are referred to as **variables.**\n    \n---\n\n:::{.nonincremental}\n- So, to summarize, each row of the data matrix corresponds to a unique observational unit, and each column corresponds to a unique variable.\n:::\n\n- Now, it will not always be immediately obvious what each variable in a dataset represents.\n\n    - As Data Scientists, it is absolutely crucial that we understand our data as best as possible before embarking on any analyses, explorations, etc.\n    \n- As such, most datasets come equipped with a so-called **data dictionary**, which lists the variables included in the dataset as well as a brief description of each variable.\n\n---\n\n:::{.nonincremental}\n- For example, the data dictionary for the `palmerpenguins` dataset might be formatted as:\n:::\n\n:::{style=\"font-size:27px\"}\n| **Variable** | **Description** |\n|:------------:|:---------------:|\n| `species` | The species of penguin (either Adelie, Chinstrap, or Gentoo) |\n| `island` | The island on which the penguin was found (either Biscoe, Dream, or Torgersen) |\n| `bill_length_mm` | The length (millimeters) of the penguin's bill |\n| `bill_depth_mm` | The depth (in millimeters) of the penguin's bill |\n| `flipper_length_mm` | The length (in millimeters) of the penguin's flipper |\n| `body_mass_g` | The mass (in grams) of the penguin |\n| `sex` | The sex of the penguin (either Male or Female) |\n| `year` | The year in which the penguin was observed |\n:::\n\n---\n\n:::{.nonincremental}\n- So, to summarize, the data matrix of the `palmerpenguins` dataset consists of 344 observational units on 8 different variables.\n:::\n\n\n- If we look at the different variables contained in the `palmerpenguins` dataset, we can see some qualitative differences.\n    \n    - For instance, the observations of `species` are all words/phrases whereas the observations of `bill_length_mm` are numbers.\n    \n    - This leads us to an important remark: there are different kinds of variables! Let's talk about how to classify these different types.\n\n# Classifying Variables\n\n## Numerical vs. Categorical\n\n-   **Numerical variables** are variables whose observations consist of numbers.\n\n    -   Examples: heights, temperatures, number of free throws, etc.\n\n-   Not all variables are numerical. For example, I could take a poll asking people's **opinions** on the movie *Avatar: The Way of Water*- the observations of this variable will most certainly not be numerical. \n\n    - Rather, the observations of this variable will fall into one of a series of fixed *categories* (e.g. \"Enjoyed the movie\", \"Neutral about the movie\", and \"Hated the movie\").\n    \n    - As such, we describe non-numerical variables as **categorical variables**.\n\n## A Note on Language {style=\"font-size:32px\"}\n\n- Question: can we say that *data* is numerical? Or, can we say we have \"categorical data\"?\n\n- Sure- if our data consists of just a single variable! \n\n- That is to say- the classification terms we learned (and will learn) can be used to describe *data*, _provided our data contains only one variable_.\n\n- The definition of data we are using (i.e. in the context of the data matrix) is that data is comprised of *several* variables. As such, we cannot simply take the classification of variables and apply that to the entire dataset (unless our dataset consists of only one variable).\n    \n    - This may seem like a subtle point... and it is! I'm just pointing it out so you are aware of it.\n\n------------------------------------------------------------------------\n\n## Continuous vs. Discrete Variables\n\n-   There is a way we can further subdivide numerical variables.\n\n-   As an example, let us consider two different variables, both of which are numerical: heights, and number of accidents on a stretch of highway.\n\n    -   It is perfectly conceivable to observe a height of 5.15 feet, or 5.1302 feet, or 5.02391829 feet. In other words, there are an infinite number of possible heights between, say, 5 feet and 6 feet.\n\n    -   On the other hand, it doesn't make sense to talk about \"1.5 accidents\" occurring on a stretch of highway; the number of accidents needs to be an integer.\n\n------------------------------------------------------------------------\n\n::: callout-note\n## Terminology\n\n<h2>Continuous vs. Discrete Variables</h2>\n\n::: {style=\"font-size: 30px\"}\nIf the possible values a numerical variable can take has \"jumps\", then it is a discrete variable. Otherwise, it is a continuous variable.\n:::\n:::\n\n-   So, for example, \"height\" is a continuous variable whereas \"number of accidents\" is a discrete variable.\n\n    -   This is because a height measurement could be any positive number, whereas the number of accidents cannot be, say, 2.5; i.e. the possible values of the \"number of accidents\" has jumps at every positive integer value.\n\n## Ordinal vs. Nominal Variables\n\n-   Just as there was a way to subdivide numerical variables, there is a way to further subdivide categorical variables as well.\n\n-   As an example, consider the following two categorical variables: color, and letter grades (i.e. A, B^+^, etc.)\n\n    -   Firstly, I hope you can see that both of these variables are indeed categorical: there are only a fixed set of values that \"color\" and \"letter grade\" can take, with nothing in between.\n\n    -   Now, clearly letter grades can be ordered: that is, an A is better than a B, which is *better* than a C, and so on and so forth.\n\n    -   In contrast, \"green\" isnt inherently *better* than \"red\", which isn't inherently *better* than \"grey\", and so on and so forth.\n\n------------------------------------------------------------------------\n\n::: callout-note\n## Terminology\n\n<h2>Ordinal vs. Nominal Variables</h2>\n\n::: {style=\"font-size: 30px\"}\nIf the possible values a categorical variable can take has a natural ordering, we call the variable **ordinal**. Otherwise, we say it is **nominal**.\n:::\n:::\n\n-   So, for example, \"letter grades\" are ordinal whereas \"color\" is nominal.\n\n------------------------------------------------------------------------\n\n## Full Classification Scheme\n\n::: nonincremental\n-   Here is a diagram of the full classification scheme:\n:::\n\n```{dot}\n//| fig-width: 10\n//| fig-height: 4\ndigraph data_classification {\n    layout = dot\n    rankdir = UD\n    splines = false\n    bgcolor = \"#f0ebd8\"\n    edge [arrowsize = 0.5, color = coral4]\n  \nsubgraph cluster_main {\n  color = transparent\n  node [color=transparent, style = filled, fillcolor = cornsilk, shape = egg];\n  \n  Data [label = \"Variable\"]\n  \n  subgraph cluster_0 {\n   color = transparent\n    node [color=transparent, style = filled, fillcolor = aquamarine3, shape = egg];\n    \n    numerical [label = \"Numerical\"]\n    \n    subgraph cluster_1 {\n      color = transparent\n      node [color = transparent, style = filled, fillcolor = bisque1, shape = egg];\n      \n        continuous [label = \"Continuous\"]\n        discrete [label = \"Discrete\"]\n    }\n    \n    {numerical} -> continuous\n    {numerical} -> discrete\n  }\n  \n  subgraph cluster_2 {\n   color = transparent\n    node [color=transparent, style = filled, fillcolor = aquamarine3, shape = egg];\n    \n    categorical [label = \"Categorical\"]\n    \n    subgraph cluster_3 {\n      color = transparent\n      node [color = transparent, style = filled, fillcolor = bisque1, shape = egg];\n      \n        nominal [label = \"Nominal\"]\n        ordinal [label = \"Ordinal\"]\n    }\n    \n    {categorical} -> nominal\n    {categorical} -> ordinal\n  }\n  \n  \n  }\n  \n  {Data} -> numerical\n  {Data} -> categorical\n}\n```\n\n------------------------------------------------------------------------\n\n## Time for an Exercise!\n\n::: callout-tip\n## Exercise 1\n\n::: {style=\"font-size: 30px\"}\nClassify each of the following variables as either discrete, continuous, ordinal, or nominal.\n\n::: nonincremental\n-   The number of times a computer program returns an error\n-   The time it takes an experienced swimmer to complete 4 laps of a pool\n-   The favorite flavor of donut of a randomly selected person\n-   The months of the year, as written in MM format (e.g. \"01\" for \"January\", \"02\" for \"February\", etc.)\n:::\n\nDiscuss with your neighbors!\n:::\n:::\n\n## Important Note\n\n- It is important to note that categorical data can be *encoded* using numbers (as we saw in the previous slide).\n\n    - Indeed, this is a fairly common practice as computers are more adept at dealing with numbers than things like words or symbols. \n    \n    - As such, when classifying data, it is not always enough to just check whether the data consists of numbers or not- it is important to think critically about what the data itself represents. \n    \n    - As a quick rule-of-thumb: check whether adding two numbers in your dataset makes interpretive sense. 12in $+$ 13in is 15in, whereas `blue` + `gold` does not equal anything, regardless of whether `blue` is being encoded as `0` and `gold` is being encoded as `1`.\n\n# Summarizing Data\n\n## Real-World Data Set {style=\"font-size:32px\"}\n\n- Let's return to the `palmerpenguins` dataset. \n- Specifically, let's examine the `species` variable:\n\n:::{.fragment}\n```{r, message = F, echo = F}\n#| class-output: hscroll\n\nlibrary(palmerpenguins)\npenguins$species\n```\n\n```{css, echo=FALSE}\n.hscroll {\n  overflow-x: auto;\n  white-space: nowrap;\n}\n```\n:::\n\n---\n\n:::{.nonincremental}\n- That's a lot of information!\n:::\n- Indeed, trying to draw conclusions about the data using the data in its *entirety* is often not a good idea. \n- Rather, we would like to find different ways to *summarize*, or *describe* our data.\n\n## Descriptive Statistics \n\n:::{.nonincremental}\n- This is the goal of **Descriptive Statistics**- to find different summarizing techniques to *desribe* the data.\n:::\n\n- There are two ways we can seek to summarize data: numerically (using numbers), and graphically. \n\n- Let's start with the latter- that is, let's discuss how we might summarize our data using graphs.\n\n# Graphical Summaries {background-color=\"black\" background-image=\"https://media3.giphy.com/media/LedVYzRx24nkI/giphy.gif?cid=ecf05e47e33eyorvdby4yoz750pdnhwi0l1s73mo68asau3c&rid=giphy.gif&ct=g\" background-size=\"contain\"}\n\n<!-- # Graphical Summaries {background-color=\"black\" background-image=\"https://media1.giphy.com/media/3o6MbrACMlFCny8zmw/giphy.gif?cid=ecf05e474pzqjvwrr3qujf8hxpswv63bbdw2pp9tes7870sm&rid=giphy.gif&ct=g\" background-size=\"contain\"} -->\n\n## Back To Penguins\n\n- Here is the `species` variable one more time:\n\n:::{.fragment}\n```{r, message = F, echo = F}\n#| class-output: hscroll\n\nlibrary(palmerpenguins)\npenguins$species\n```\n\n```{css, echo=FALSE}\n.hscroll {\n  overflow-x: auto;\n  white-space: nowrap;\n}\n```\n:::\n\n---\n\n:::{.nonincremental}\n- We see there are three distinct species present in the dataset: Adelie, Chinstrap, and Gentoo.\n:::\n\n- As such, one way we could summarize our data is by reporting how many penguins of each species were observed.\n\n- Using a computing software, finding these counts is relatively easy.\n\n:::{.fragment}\n```{r, message = F, echo = F}\ntable(penguins$species)\n```\n:::\n\n- So, there were 152 Adelie penguins, 68 Chinstrap penguins, and 124 Gentoo penguins.\n\n- This kind of table is called a **frequency table**, and is a great way to summarize categorical data.\n\n---\n\n:::{.nonincremental}\n- Okay... but where's the graph?\n:::\n\n- Here's an idea: let's take our frequency table, and convert *it* to a graph.\n- Specifically, let's draw 3 boxes/rectangles, one for each species.\n    - Let's make the height of each rectangle proportional to the corresponding frequency from our frequency table:\n\n---\n\n\\\n\n```{r, message = F}\nlibrary(tidyverse)\nlibrary(ggthemes)\n\ndata.frame(table(penguins$species)) %>%\n  rename(species = Var1, freq = Freq) %>%\n  ggplot(aes(x = species, y = freq)) +\n  geom_bar(stat = \"identity\",\n           fill = \"#7f9ab5\") +\n  theme_economist(base_size = 18) +\n  theme(panel.background = element_rect(\"#f0ebd8\"),\n        plot.background = element_rect(fill = \"#f0ebd8\"),\n        axis.title.x = element_text(size = 16,\n                                    margin = margin(\n                                      t = 20, \n                                      r = 0,\n                                      b = 0, \n                                      l = 0)),\n        axis.title.y = element_text(size = 16)\n  )\n```\n\n## Bargraphs/Barplots\n\n:::{.nonincremental}\n- This is an example of what is known as a **bargraph** or **barplot**.\n:::\n\n:::{.callout-note}\n## **Result**\n::: {style=\"font-size: 30px\"}\nA bargraph is the best type of visualization for categorical data.\n:::\n:::\n\n- In general, if you have $k$ categories, then you will have $k$ bars in your bargraph, each with height propotional to the number of observations within the corresponding category.\n\n- As you can see, computing software is very useful when it comes to data visualization! In a few weeks, you will explore how to generate visualizations of your own in Python during Lab. \n\n---\n\n## Time For Another Exercise!\n\n::: callout-tip\n## Exercise 2\n\n::: {style=\"font-size: 24px\"}\nA recent survey asked 120 different PSTAT students what their favorite color is. The bargraph of the results is displayed below:\n\n```{r, fig.height = 3.4, fig.width = 10}\n#| echo: false\n\nset.seed(123)\ncols <- sample(c(\"red\", \"blue\", \"green\", \"orange\", \"purple\", \"gold\", \"other\"), 120, replace = T, prob = c(0.15, 0.15, 0.13, 0.14, 0.16, 0.13, 0.14))\ncols <- factor(cols,\n               levels = c(\"red\", \"blue\", \"green\", \"orange\", \"purple\", \"gold\", \"other\"),\n                         ordered = T)\n\ndata.frame(table(cols)) %>%\n  ggplot(aes(x = cols, y = Freq)) +\n  geom_bar(stat = \"identity\",\n           fill = \"#7f9ab5\") +\n  theme_economist(base_size = 18) +\n  theme(panel.background = element_rect(\"#f0ebd8\"),\n        plot.background = element_rect(fill = \"#f0ebd8\"),\n        axis.title.x = element_text(size = 16,\n                                    margin = margin(\n                                      t = 20, \n                                      r = 0,\n                                      b = 0, \n                                      l = 0)),\n        axis.title.y = element_text(size = 16)\n  ) +\n  ylab(\"freq\")\n```\n\nApproximately what proportion of the students in the sample reported either blue or gold as their favorite color? Discuss with your neighbor!\n:::\n:::\n\n## Leadup\n\n:::{.nonincremental}\n- All of our discussions above were related to categorical variables.\n:::\n\n- As we discussed at the beginning of this lecture, not all variables are categorical- how do we visualize numerical variables?\n\n- Again, I find it useful to consider a concrete example: this time, let's use the `bill_length_mm` variable from the `palmerpenguins` dataset.\n\n---\n\n\n```{r, message = F, echo = F}\n#| class-output: hscroll\n\nlibrary(palmerpenguins)\npenguins$bill_length_mm\n```\n\n```{css, echo=FALSE}\n.hscroll {\n  overflow-x: auto;\n  white-space: nowrap;\n}\n```\n\n- In some ways, this is an even bigger mess than the `species` variable- look at all those decimals!\n\n---\n\n- Because this variable is continuous, we intuitively know that it's highly unlikely to have 2 or more observations that are the same.\n\n    - In other words, the chances of finding two different penguins with exactly the same bill length, down to the decimal, is highly unlikely.\n\n- As such, we cannot construct a frequency table like we did with our categorical variable from before.\n\n- But, here's a thought: there are probably multiple penguins that have bill lengths between, say, 30 and 35 mm. Similarly, there are probably multiple penguins that have bill lengths between 35 and 40 mm.\n\n- So, what if we viewed our continuous variable as being, in a sense, categorical, with categories \"between 30 and 35\", \"between 35 and 40\", etc.?\n\n## Discretization/Binning\n\n:::{.nonincremental}\n- This is what is known as **discretizing** or **binning** our variable.\n:::\n\n- In other words, when we discretize our data, we carve it up into a bunch of chunks of equal width and see how many observations fall in each chunk.\n\n    - The width of each chunk is what we call the **binwidth**. For example, if my categories are \"between 30 and 35\", \"between 35 and 40\", etc., then the binwidth is 5mm as each category spans a width of 5mm.\n\n\n---\n\n:::{.nonincremental}\n- Using a binwidth of 5, here is what our `bill_length_mm` variable becomes:\n:::\n\n```{r}\nbins <- c(\"[30, 35]\", \"(35, 40]\", \"(40, 45]\", \"(45, 50]\", \"(50, 55]\", \"(55, 60]\")\nbill_length_mm <- na.omit(penguins$bill_length_mm)\ncounts <- hist(bill_length_mm, plot = F, breaks = 8)$counts\n\nnames(counts) <- bins\ncounts\n```\n- So, for example, there were 11 penguins with bill lengths between 30 and 35mm, 89 between 35 and 40, and so on and so forth.\n\n- By the way, I am using interval notation in the bin names above. So, when we write $(35, 40]$ we mean all numbers between 35 and 40, including 35 but excluding 40.\n\n    - The reason for this is that if a datapoint falls on the boundary of a bin, we conventionally assign it to the left (lower) bin.\n\n    - If you are not familiar with interval notation, I have posted some supplementary materials to the website.\n  \n---\n\n:::{.nonincremental}\n- We're almost ready for our graph!\n:::\n\n- First, however, note that the table on the previous slide isn't really the same thing as the frequency table we saw when exploring the `species` variable. \n\n    - Largely, this is due to the fact that different binwidths lead to different tables! \n    \n- As such, we will refer to this type of table (i.e. the frequencies after binning a continuous variable) as a **distribution table**.\n\n- With this terminology in mind, we can use the distribution table much in the same way we used the frequency table to construct a graph- i.e. we will draw as many rectangles as there are bins, and have the height of each rectangle proportional to the corresponding frequency in the distribution table.\n\n---\n\n```{r}\n#| echo: false\n\npenguins %>%\n  ggplot(aes(x = bill_length_mm)) +\n  geom_histogram(col = \"white\",\n                 breaks = seq(30, 60, by = 5)) +\n  theme_economist(base_size = 18) +\n  theme(panel.background = element_rect(\"#f0ebd8\"),\n        plot.background = element_rect(fill = \"#f0ebd8\"),\n        axis.title.y = element_text(size = 16,\n                                    margin = margin(\n                                      t = 0, \n                                      r = 10,\n                                      b = 0, \n                                      l = 0)),\n        axis.title.x = element_text(size = 16)\n  ) +\n  ggtitle(\"Distribution of Bill Lengths\")\n\n```\n\n- This type of plot is called a **histogram**.\n\n---\n\n:::{.callout-note}\n## **Result**\n::: {style=\"font-size: 30px\"}\nA histogram is the best type of visualization for continuous variables.\n:::\n:::\n\n- By the way, you can still construct histograms for discrete variables as well! In the case of a discrete variable, however, we don't really need to bin our data, because if our data can only take a fixed number of values then it is likely we will have multiple observations of any particular value.\n\n## The Importance of Binwidth\n\n- Notice that our notion of a histogram is intimately tied with our choice of binwidth. \n\n- Different binwidths can produce wildly different histograms!\n\n- Here is a <a href = \"https://epm927.shinyapps.io/Histogram_Binwidths/\" target = \"_blank\">demo</a>\n\n- In practice, it is a good idea to play around with different binwidths to find one that results in a histogram that displays a moderate amount of detail without becoming so detailed as to lose sight of the bigger picture.\n\n---\n\n:::{.callout-tip}\n## Exercise 3\n\n::: {style=\"font-size: 24px\"}\nConsider the following histogram of the length of flippers in the `palmerpenguins` dataset:\n```{r, fig.height = 3.25, fig.width = 10}\npenguins %>%\n  ggplot(aes(x = flipper_length_mm)) +\n  geom_histogram(col = \"white\",\n                 breaks = seq(170, 240, by = 10)) +\n  theme_economist(base_size = 18) +\n  theme(panel.background = element_rect(\"#f0ebd8\"),\n        plot.background = element_rect(fill = \"#f0ebd8\"),\n        axis.title.y = element_text(size = 16,\n                                    margin = margin(\n                                      t = 0, \n                                      r = 10,\n                                      b = 0, \n                                      l = 0)),\n        axis.title.x = element_text(size = 16)\n  ) +\n  scale_x_continuous(\n    breaks = seq(170, 240, by = 10)\n  )\n\n```\n::: nonincremental\n- What binwidth was used to generate the above histogram?\n- What proportion of penguins had flippers between 190 and 210 mm long? (Remember there were 344 penguins included in the dataset) \n:::\n\nDiscuss with your neighbors!\n:::\n:::\n\n## Boxplots {style=\"font-size:24px\"}\n\n- It turns out there is another way to summarize numerical data visually: using what is known as a **boxplot**.\n\n- Boxplots can be a seem a bit peculiar at first, so let's take a look at one together. Before diving back into the `palmerpenguins` dataset, let's look at a slightly different dataset.\n\n    - This dataset contains only one variable, which records the scores (out of 100 points) of 140 different students on a final exam.\n\n:::{.fragment}\n```{r, message = F, echo = F}\n#| class-output: hscroll\n\nset.seed(130)\nx <- rnorm(140, 80, 5)\nx <- round(x, 3)\nx\n```\n\n```{css, echo=FALSE}\n.hscroll {\n  overflow-x: auto;\n  white-space: nowrap;\n}\n```\n:::\n\n---\n\n:::{.nonincremental}\n- Here is a histogram of these scores...\n:::\n\n```{r}\ndata.frame(x) %>%\n  ggplot(aes(x = x)) +\n  geom_histogram(col = \"white\", bins = 15) +\n  theme_economist(base_size = 18) +\n  theme(panel.background = element_rect(\"#f0ebd8\"),\n        plot.background = element_rect(fill = \"#f0ebd8\"),\n        axis.title.y = element_text(size = 16,\n                                    margin = margin(\n                                      t = 0, \n                                      r = 10,\n                                      b = 0, \n                                      l = 0)),\n        axis.title.x = element_text(size = 16)\n  ) +\n  ggtitle(\"Histogram of Scores\")\n```\n\n---\n\n:::{.nonincremental}\n- ... and here is a boxplot\n:::\n\n```{r}\ndata.frame(x) %>%\n  ggplot(aes(x = x)) +\n  stat_boxplot(geom = \"errorbar\", \n               width = 0.25,\n               linewidth = 1) +\n  geom_boxplot(fill =  \"#7f9ab5\", \n               size = 1,\n               outlier.size = 4) +\n  theme_economist(base_size = 18) +\n  theme(panel.background = element_rect(\"#f0ebd8\"),\n        plot.background = element_rect(fill = \"#f0ebd8\"),\n        axis.title.y = element_text(size = 16,\n                                    margin = margin(\n                                      t = 0, \n                                      r = 10,\n                                      b = 0, \n                                      l = 0)),\n        axis.title.x = element_text(size = 16),\n        axis.text.y = element_blank()\n  ) +\n  ylim(c(-0.75, 0.75)) +\n  ggtitle(\"Boxplot of Scores\")\n```\n\n## Anatomy of a Boxplot\n\n\\\n\n![](boxplot.svg)\n\n## Understanding Boxplots\n\n- Let's discuss each of the quantities represented on the boxplot separately.\n\n- Before we do, there's a bit of math we need to cover.\n\n- The first quantity we will define is a term you may have heard before- **percentile.** \n\n- Let's return to our histogram of scores (since we're a bit more comfortable with reading histograms than boxplots, at this point)\n\n---\n\n```{r, fig.height = 4}\ndata.frame(x) %>%\n  ggplot(aes(x = x)) +\n  geom_histogram(col = \"white\", bins = 15) +\n  theme_economist(base_size = 18) +\n  theme(panel.background = element_rect(\"#f0ebd8\"),\n        plot.background = element_rect(fill = \"#f0ebd8\"),\n        axis.title.y = element_text(size = 16,\n                                    margin = margin(\n                                      t = 0, \n                                      r = 10,\n                                      b = 0, \n                                      l = 0)),\n        axis.title.x = element_text(size = 16)\n  ) +\n  ggtitle(\"Histogram of Scores\") +\n  geom_vline(xintercept = 90,\n             size = 1,\n             col = \"red\")\n```\n\n- Now, consider the score of a hypothetical student called Mindy. Suppose Mindy received a score of 90% on this exam.\n\n- Following the steps we used in Exercise 3, we can compute the proportion of students who scored *lower* than Mindy to be 95.71%.\n\n    - We would therefore say that Mindy's score - i.e. 90% - is at the **95.71^th^ percentile** of exam scores.\n\n\n---\n\n## Percentiles\n\n:::{.fragment}\n:::{.callout-note}\n## **Definition**\n::: {style=\"font-size: 30px\"}\nThe **_p_^th^ percentile** of a set of observations $X$ is the value $\\pi_{x, \\ p}$ such that _p_% of observations lie to the left of (i.e. are less than) $\\pi_{x, \\ p}$.\n:::\n:::\n:::\n\n- Maybe now you can see why I switched over to this data of scores- I think percentiles are sometimes easier to interpret in the context of exam scores, since they are very commonly reported with standardized testing scores (e.g. SAT, GRE, etc.)\n\n    - In the context of scores: someone who scored at the _p_^th^ percentile performed *better* than _p_\\% of all test-takers.\n    \n## Quartiles\n\n- We give a special name to the 25^th^ and 75^th^ percentiles of a set of observations- we call these the **first quartile** and **third quartile**, respectively, and use the notation $Q_1$ and $Q_3$ to denote them, respectively.\n\n    - So, $Q_1$ is the value such that 25% of observations are less than $Q_1$, and $Q_3$ is the value such that 75% of observations are less than $Q_3$\n\n- The second quartile (i.e. the 50^th^ percentile) is called the **median**.\n\n    - As such, the median is the value that \"splits the data in half\".\n    \n    - We'll talk more about the median in the next lecture.\n\n## Small Caveat\n\n- I should quickly mention one small caveat- computing softwares often use a different procedure for computing quartiles.\n\n- This procedure is quite long and complicated, and is based off an entire paper written back in the 90's. \n\n- For example, if we consider the set $S = \\{1, 2, 3, 4, 5, 6\\}$, we would (based on the definition from the previous slide) call the first quartile $2$, whereas most softwares would return a value of $2.25$.\n\n    - I'll show you on the chalkboard why the first quartile is $2$.\n\n- **Don't worry about why this is**- whenever we talk about quartiles in this class, you can just think of the definition I posed on the previous slide.\n\n\n## Whiskers\n\n- Finally, we discuss the role of the whiskers on the boxplot.\n\n- There are several different conventions for how far the whiskers extend. In some conventions, the whiskers extend to the minimum and maximum values of the data.\n\n- The convention we will use is the following: **the whiskers will never reach farther than $\\boldsymbol{1.5 \\times (Q_3 - Q_1)}$**.\n\n    - What this means is that there may be points in our dataset that lie beyond the reach of the whiskers. These points are what we call **outliers**.\n\n## Whiskers {style=\"font-size:30px\"}\n\n:::{.nonincremental}\n- The rationale for constructing the whiskers in this way is to try and highlight any points that are unusually distant from the rest of the data.\n:::\n\n- For example, returning to our dataset of scores, we can see that though the median score was around 80.3\\% there was one person who scored a 97.9\\%. Because this score is unusually large, we would label it an outlier.\n\n:::{.fragment}\n```{r, fig.width = 8, fig.height = 3}\ndata.frame(x) %>%\n  ggplot(aes(x = x)) +\n  stat_boxplot(geom = \"errorbar\", \n               width = 0.25,\n               linewidth = 1) +\n  geom_boxplot(fill =  \"#7f9ab5\", \n               size = 1,\n               outlier.size = 4) +\n  theme_economist(base_size = 18) +\n  theme(panel.background = element_rect(\"#f0ebd8\"),\n        plot.background = element_rect(fill = \"#f0ebd8\"),\n        axis.title.y = element_text(size = 16,\n                                    margin = margin(\n                                      t = 0, \n                                      r = 10,\n                                      b = 0, \n                                      l = 0)),\n        axis.title.x = element_text(size = 16),\n        axis.text.y = element_blank()\n  ) +\n  ylim(c(-0.75, 0.75)) +\n  ggtitle(\"Boxplot of Scores\")\n```\n:::\n\n## Time for an Exercise!  {style=\"font-size:20px\"}\n\n::: callout-tip\n## Exercise 4\n\n::: {style=\"font-size: 20px\"}\nHere is a boxplot of the `bill_length_mm` variable from the `palmerpenguins` dataset:\n\n```{r, fig.height = 3.25, fig.width = 7}\npenguins %>%\n  ggplot(aes(x = bill_length_mm)) +\n  stat_boxplot(geom = \"errorbar\", \n               width = 0.25,\n               linewidth = 1) +\n  geom_boxplot(fill =  \"#7f9ab5\", \n               linewidth = 1,\n               outlier.size = 4) +\n  theme_economist(base_size = 18) +\n  theme(panel.background = element_rect(\"#f0ebd8\"),\n        plot.background = element_rect(fill = \"#f0ebd8\"),\n        axis.title.y = element_text(size = 16,\n                                    margin = margin(\n                                      t = 0, \n                                      r = 10,\n                                      b = 0, \n                                      l = 0)),\n        axis.title.x = element_text(size = 16),\n        axis.text.y = element_blank()\n  ) +\n  ylim(c(-0.75, 0.75))\n```\n:::\n\n:::{.nonincremental}\n- What is the median bill length?\n- Approximately what percent of penguins had bills shorter than 37mm in length?\n- Are there any outliers?\n:::\n:::\n\n# Lecture Summary\n\n## Summary {style=\"font-size:32px\"}\n\n- We started off by talking about the structure of data, and the data matrix.\n\n- We then discussed how to classify variables.\n\n- Next, we explored graphical methods for summarizing data.\n\n    - Bargraphs are best-suited for categorical data\n    \n    - Histograms and boxplots are best-suited for numerical data\n\n- We also introduced the notions of percentiles, the median, and outliers.\n\n- Next time we'll discuss how to visualize the relationship between two variables.\n\n- We'll also discuss some numerical summaries for data, including the mean, median, standard deviation, and IQR.\n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":"mathjax","slide-level":2,"to":"revealjs","incremental":true,"output-file":"Lec01_v2.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.2.335","auto-stretch":true,"title":"PSTAT 5A: Lecture 01","subtitle":"Descriptive Statistics, Part I","author":"Ethan P. Marzban","date":"04/04/23","editor":"source","title-slide-attributes":{"data-background-image":"5a_hex.png","data-background-size":"contain","data-background-opacity":"0.5","data-background-position":"left"},"theme":["default","custom.scss"],"logo":"5a_hex.png","template-partials":["title-slide.html"]}}}}